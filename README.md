# ML-Bootcamp

### 1. Linear and Logistic Regression
a).Tried writing the mathematical code of gradient descent, by using matrices ( by numpy library), using for loops for iterations and for nested loop for calculating theta (parameter) matrix in a single iteration.

b). Normalized the data to bring it into a single scale (0 to 1), cleaved the data into training and test sets by using the sklearn library's train test split.

c). Calculated and printed the cost/error using the cost function.

d). Defined a single function for gradient descent and cost function for simplicity of inputing the data by the user (like how many iterations, learning rate, etc)

e). Plotted an error v/s iterations graph using the matplotlib library to make the work presentable.

##### Observations:
Tried many values of iterations and learning rate, to try and observe what change does it cause in the error/cost and how does the graph of error v/s iterations varies with their different values.

